{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/STAT 121A/AC 209A/CSCI E-109A: Homework 6\n",
    "# Reg-Logistic Regression, ROC, and Data Imputation\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2017**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, Rahul Dave, Margo Levine\n",
    "\n",
    "---\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- Do not include your name(s) in the notebook if you are submitting as a group. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your partner's name (if you submit separately): Scott Shaffer \n",
    "\n",
    "Enrollment Status (109A, 121A, 209A, or E109A): 109A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, Math, Latex\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Breast Cancer Detection\n",
    "\n",
    "In this homework, we will consider the problem of early breast cancer detection from X-ray images. Specifically, given a candidate region of interest (ROI) from an X-ray image of a patient's breast, the goal is to predict if the region corresponds to a malignant tumor (label 1) or is normal (label 0). The training and test data sets for this problem is provided in the file `hw6_dataset.csv`. Each row in these files corresponds to a ROI in a patient's X-ray, with columns 1-117 containing features computed using standard image processing algorithms. The last column contains the class label, and is based on a radiologist's opinion or a biopsy. This data was obtained from the KDD Cup 2008 challenge.\n",
    "\n",
    "The data set contain a total of 69,098 candidate ROIs, of which only 409 are malignant, while the remaining are all normal. \n",
    "\n",
    "*Note*: be careful of reading/treating column names and row names in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Beyond Classification Accuracy\n",
    "\n",
    "\n",
    "0.  Split the data set into a training set and a testing set.  The training set should be 75% of the original data set, and the testing set 25%.  Use `np.random.seed(9001)`.\n",
    "\n",
    "1. Fit a logistic regression classifier to the training set and report the  accuracy of the classifier on the test set. You should use $L_2$ regularization in logistic regression, with the regularization parameter tuned using cross-validation. \n",
    "    1. How does the fitted model compare with a classifier that predicts 'normal' (label 0) on all patients? \n",
    "    2. Do you think the difference in the classification accuracies are large enough to declare logistic regression as a better classifier than the all 0's classifier? Why or why not?\n",
    "    \n",
    "For applications with imbalanced class labels, in this case when there are many more healthy subjects ($Y=0$) than those with cancer ($Y=1$), the classification accuracy may not be the best metric to evaluate a classifier's performance. As an alternative, we could analyze the confusion table for the classifier. \n",
    "\n",
    "<ol start=\"3\">\n",
    "<li> Compute the confusion table for both the fitted classifier and the classifier that predicts all 0's.</li>\n",
    "<li> Using the entries of the confusion table compute the *true positive rate* and the *true negative rate* for the two classifiers. Explain what these evaluation metrics mean for the specific task of cancer detection. Based on the observed metrics, comment on whether the fitted model is better than the all 0's classifier.</li>\n",
    "<li> What is the *false positive rate* of the fitted classifier, and how is it related to its true positive and true negative rate? Why is a classifier with high false positive rate undesirable for a cancer detection task?</li>\n",
    "</ol>\n",
    "*Hint:* You may use the `metrics.confusion_matrix` function to compute the confusion matrix for a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    68688\n",
      "1.0      409\n",
      "Name: 0.000000000000000000e+00, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9001)\n",
    "df = pd.read_csv('./data/hw6_dataset.csv')\n",
    "\n",
    "#  How (im)balanced is the data?\n",
    "print(df['0.000000000000000000e+00'].value_counts())\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]\n",
    "\n",
    "ytrain = data_train.iloc[:,-1]\n",
    "Xtrain = data_train.drop(data_test.columns[len(data_test.columns)-1], axis=1)\n",
    "\n",
    "ytest = data_test.iloc[:,-1]\n",
    "Xtest = data_test.drop(data_test.columns[len(data_test.columns)-1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995084269663\n",
      "17088\n",
      "104\n",
      "Percent non-zero: \n",
      "0.9939138576779026\n"
     ]
    }
   ],
   "source": [
    "logregcv = LogisticRegressionCV(penalty='l2')\n",
    "logregcv.fit(Xtrain, ytrain)\n",
    "\n",
    "print(logregcv.score(Xtest, ytest))\n",
    "\n",
    "print(len(ytest))\n",
    "all_values = len(ytest)\n",
    "positive_values = np.count_nonzero(ytest)\n",
    "print(np.count_nonzero(ytest))\n",
    "print(\"Percent non-zero: \")\n",
    "print(1.0-(positive_values/all_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer cases predicted:\n",
      "36\n",
      "Actual cancer cases:\n",
      "104\n",
      "Confusion Matrix:\n",
      "[[16976     8]\n",
      " [   76    28]]\n",
      "\n",
      "True Positive Rate:\n",
      "0.269230769231\n",
      "\n",
      "True Negative Rate:\n",
      "0.999528968441\n",
      "\n",
      "False Positive Rate:\n",
      "0.000471031559114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_preds = logregcv.predict(Xtest)\n",
    "print(\"Cancer cases predicted:\")\n",
    "print(np.count_nonzero(test_preds))\n",
    "print(\"Actual cancer cases:\")\n",
    "print(positive_values)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "C = confusion_matrix(ytest, test_preds, labels=None)\n",
    "print(C)\n",
    "\n",
    "# From sklearn documentation: \n",
    "# the count of true negatives is C_{0,0}, false negatives is C_{1,0}, \n",
    "# true positives is C_{1,1} and false positives is C_{0,1}.\n",
    "\n",
    "# Sensitivity or TPR = TP / P = TP / (TP + FN)\n",
    "print(\"\\nTrue Positive Rate:\")\n",
    "print(C[1][1] / (C[1][1] + C[1][0]))\n",
    "\n",
    "# Specificity or TNR = TN / N = TN / (TN + FP)\n",
    "print(\"\\nTrue Negative Rate:\")\n",
    "print(C[0][0] / (C[0][0] + C[0][1]))\n",
    "\n",
    "# FPR = FP / N = FP / (FP + TN)\n",
    "print(\"\\nFalse Positive Rate:\")\n",
    "print(C[0][1] / (C[0][1] + C[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: How does the fitted model compare with a classifier that predicts 'normal' (label 0) on all patients?\n",
    "\n",
    "The accuracy of the fitted model using logistic regression (0.9954) is just marginally better than the accuracy of the all 0's classifier (0.9938).  Both exhibit almost near perfect accuracy (1.0), though, this is not surprising given the highly imbalanced nature of the data set (68689 - 0 and 409 - 1 for the original data set), just predict the most common response, in this case, 0.\n",
    "\n",
    "#### Q: Do you think the difference in the classification accuracies are large enough to declare logistic regression as a better classifier than the all 0's classifier? Why or why not? \n",
    "\n",
    "Based on the classification accuracy metric alone, we don't think the difference in classification accuracies (0.2%) is large enough to affirm logistic regression as the better classifier.\n",
    "\n",
    "#### Q: Explain what these evaluation metrics (true positive rate and the true negative rate) mean for the specific task of cancer detection. \n",
    "\n",
    "The true positive rate, also known as Sensitivity, is the ability of a test to correctly diagnose patients who have a disease (malignant tumor), given they have the disease:\n",
    "\n",
    "$$\\frac{True~Positive}{(True~Positive + False~Negative)}$$\n",
    "\n",
    "The true negative rate, also known as Specificity, is the ability of the test to correctly diagnose patients who don’t have the disease (malignant tumor), given they do not have the disease:\n",
    "\n",
    "$$\\frac{True~Negative}{(True~Negative + False~Positive)}$$\n",
    "\n",
    "It's worth noting that while sensitivity and specificity are easy to measure, they're not very useful in clinical practice since a clinician doesn't know if a given patient has the disease in question or not.  This is the reason why the clinician performs the diagnostic test in the first place. Instead, the clinician wants to know, given the test result, how likely is it that the patient has the disease, this is known as the positive predictive value (ppv).\n",
    "\n",
    "#### Q: Based on the observed metrics, comment on whether the fitted model is better than the all 0's classifier.\n",
    "\n",
    "A different picture emerges when we compare the confusion matrices, true positive rates, and true negative rates of the two classifiers.  When making comparisons, the fitted logistic regression classifier is clearly the superior model, based on comparing the true positive rates: 27% for the logistic regression classifier vs 0% for the all 0's classifier. Given that we're trying to identify a malignant tumor, a potentially fatal condition, the all 0's classifier will never predict a malignant tumor, making it a totally ineffective model.  \n",
    "\n",
    "The true negative rates for both classifiers are almost equivalent, at or very near to 100%: 99.96% for the fitted logistic regression classifier and 100% for the all 0's classifier.  However, for such a serious condition, we'd rather have a higher true positive rates at the expense of a lower true negative rates.  While there's definitely room for improvement in the logistic regression classifier's true positive rate, anything is better than the all 0's classifier true positive rate of 0%!\n",
    "\n",
    "#### Q: What is the *false positive rate* of the fitted classifier, and how is it related to its true positive and true negative rate? Why is a classifier with high false positive rate undesirable for a cancer detection task?\n",
    "\n",
    "False Positive Rate is the rate of false positives (do not have cancer, but the test is positive) out of all of the \"actual negatives\" -- so true negatives plus false positives. This can be written as FP/(TN+FP)\n",
    "\n",
    "$$\\frac{False~Positive}{(False~Positive + True~Negative)}$$\n",
    "\n",
    "The True Negative Rate is the rate of true negatives (people who do not have cancer, and the test is negative) over all of the actual negatives. This is equal to TN/(TN+FP), or 1 - False Positive Rate (described above)\n",
    "\n",
    "$$ False~Positive~Rate = 1 - True~Negative~Rate$$\n",
    "\n",
    "The True Positive Rate is the true positives over all the actual positives (people with cancer), so False Negatives + True Positives. The relationship between TPR and FPR/TNR is dependent on the classification model.\n",
    "\n",
    "#### Q: Why is a classifier with high false positive rate undesirable for a cancer detection task?\n",
    "\n",
    "A classifier with high false positive rate could be viewed as undesirable for a cancer detection task in the context that the patient who doesn't really have the disease (malignant tumor) will most likely undergo additional unnessary, and possibly invasive, tests/procedures and will feel stressed thinking they have the disease when they don't.\n",
    "\n",
    "We view a high false negative rate as even more undesirable than a high false positive rate in the context of cancer detection since the mistake of not detecting cancer when it's present can have extreme negative consequences for the patient's mortality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: ROC Analysis\n",
    "\n",
    "Another powerful diagnostic tool for class-imbalanced classification tasks is the Receiver Operating Characteristic (ROC) curve. Notice that the default logistic regression classifier in `sklearn` classifies a data point by thresholding the predicted class probability $\\hat{P}(Y=1)$ at 0.5. By using a different threshold, we can adjust the trade-off between the true positive rate (TPR) and false positive rate (FPR) of the classifier. The ROC curve allows us to visualize this trade-off across all possible thresholds.\n",
    "\n",
    "\n",
    "1. Display the ROC curve for the fitted classifier on the *test set*. In the same plot, also display the ROC curve for the all 0's classifier. How do the two curves compare?\n",
    "\n",
    "2.  Compute the highest TPR that can be achieved by the classifier at each of the following FPR's, and the thresholds at which they are achieved. Based on your results, comment on how the threshold influences a classifier's FPR.\n",
    "    - FPR = 0\n",
    "    - FPR = 0.1\n",
    "    - FPR = 0.5\n",
    "    - FPR = 0.9\n",
    "- Suppose a clinician told you that diagnosing a cancer patient as normal is *twice* as critical an error as diagnosing a normal patient as having cancer. Based on this information, what threshold would you recommend the clinician to use? What is the TPR and FPR of the classifier at this threshold? \n",
    "\n",
    "- Compute the area under the ROC curve (AUC) for both the fitted classifier and the all 0's classifier. How does the difference in the AUCs of the two classifiers compare with the difference between their classification accuracies in Question 1, Part 2(A)? \n",
    "\n",
    "*Hint:* You may use the `metrics.roc_curve` function to compute the ROC curve for a classification model and the `metrics.roc_auc_score` function to compute the AUC for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAK9CAYAAAD2YzurAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/dYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183fcac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plotROC(ytrue, ypreds):\n",
    "    fpr, tpr, thresholds = roc_curve(ytrue, ypreds)\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "test_scores = logregcv.predict_proba(Xtest)[:,1]\n",
    "\n",
    "yzeros = np.zeros(len(ytest))\n",
    "plt.figure(figsize = (16, 12))\n",
    "plotROC(ytest, test_scores)\n",
    "plotROC(ytest, yzeros)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FPR Threshold:            0.0\n",
      "False Positive Rate:      5.88789448893e-05\n",
      "True Positive Rate:       0.0\n",
      "Predicted Class\n",
      "Probability Threshold:    0.999904808579\n",
      "Index:                    1\n",
      "\n",
      "FPR Threshold:            0.1\n",
      "False Positive Rate:      0.10633537447\n",
      "True Positive Rate:       0.807692307692\n",
      "Predicted Class\n",
      "Probability Threshold:    0.00566066055547\n",
      "Index:                    113\n",
      "\n",
      "FPR Threshold:            0.5\n",
      "False Positive Rate:      0.537976919454\n",
      "True Positive Rate:       0.961538461538\n",
      "Predicted Class\n",
      "Probability Threshold:    0.000152379283602\n",
      "Index:                    147\n",
      "\n",
      "FPR Threshold:            0.9\n",
      "False Positive Rate:      0.987635421573\n",
      "True Positive Rate:       0.990384615385\n",
      "Predicted Class\n",
      "Probability Threshold:    6.7004874287e-09\n",
      "Index:                    157\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(ytest, logregcv.predict_proba(Xtest)[:,1])\n",
    "\n",
    "\n",
    "#  Compute the highest TPR that can be achieved by the classifier at each \n",
    "#  of the following FPRs, and note the thresholds at which they are achieved. \n",
    "FPRS = [0.0, 0.1, 0.5, 0.9]\n",
    "#  Iterate through specified FPR thresholds\n",
    "for FPR in FPRS:\n",
    "    #  Iterate through false positive rate object for the \n",
    "    #  fitted logistic regression classifier.\n",
    "    for ind, fpr1 in enumerate(false_positive_rate):\n",
    "        # Do we cross the pecified FPR threshold?\n",
    "        if fpr1 - FPR > 0:\n",
    "            # Yes, then grab values\n",
    "            print (\"\\nFPR Threshold:            \" + str(FPR))\n",
    "            print (\"False Positive Rate:      \" + str(false_positive_rate[ind]))\n",
    "            print (\"True Positive Rate:       \" + str(true_positive_rate[ind]))\n",
    "            print (\"Predicted Class\\nProbability Threshold:    \" + str(thresholds[ind]))\n",
    "            print (\"Index:                    \" + str(ind))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEKCAYAAABUsYHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKri/wOJywZVRdd8BgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d5d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a plot at the point at which \n",
    "# diagnosing a cancer patient as normal is twice as bad as diagnosing a normal patient with cancer\n",
    "# That is: False negative rate needs to be half false positive rate FNR = 1/2 FPR\n",
    "# FNR = 1-TPR\n",
    "# 1 - TPR = 1/2 FPR\n",
    "fpr, tpr, thresholds = roc_curve(ytest, test_scores)\n",
    "plt.plot(1-tpr, thresholds, label='FNR')\n",
    "plt.plot(0.5*fpr, thresholds, label='0.5 * FPR')\n",
    "plt.xlabel('Threshhold')\n",
    "plt.ylabel('Scaled FNR and FPR')\n",
    "plt.xlim(0.05, 0.2)\n",
    "plt.ylim(0.0, 0.02)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sshaffer/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:        0.116\n",
      "False Negative:   50\n",
      "False Positive:   100\n",
      "\n",
      "\n",
      "Test Confusion Matrix at threshold: 0.116\n",
      "[[16884   100]\n",
      " [   50    54]]\n",
      "\n",
      "true positive rate at threshold 0.116 :  0.519230769231\n",
      "\n",
      "false positive rate at threshold 0.116:  0.00588789448893\n"
     ]
    }
   ],
   "source": [
    "#    Computed mathematically...\n",
    "#    Diagnosing a cancer patient as normal is twice as critical an error as \n",
    "#    diagnosing a normal patient as having cancer.\n",
    "#     ==> One False Negative is 2 times less desirable than One False Positive\n",
    "#    Determine the classification threshold corresponding to this\n",
    "\n",
    "threshold = 0.0\n",
    "# Iterate through theshold range\n",
    "for threshold in np.arange(0.0, 1.0, 0.001):\n",
    "    # Determine FN and FP from confusion matrix at specified threshold\n",
    "    tn_logregCV, fp_logregCV, fn_logregCV, tp_logregCV = confusion_matrix(ytest, \n",
    "                                                                      (np.round(logregcv.predict_proba(Xtest)[:,1] - threshold + 0.5)),\n",
    "                                                                      labels = None).ravel()\n",
    "    #  Is False Positive // False Negative = 2?\n",
    "    if ( fp_logregCV % fn_logregCV == 0)  and ( fp_logregCV // fn_logregCV == 2):\n",
    "        # Yes, display threshold, FN, and FP\n",
    "        print (\"Threshold:        \" + str(threshold))\n",
    "        print (\"False Negative:   \" + str(fn_logregCV))\n",
    "        print (\"False Positive:   \" + str(fp_logregCV))\n",
    "        break\n",
    "print (\"\\n\\nTest Confusion Matrix at threshold: \" + str(threshold))\n",
    "print (confusion_matrix(ytest, (np.round(logregcv.predict_proba(Xtest)[:,1] - threshold + 0.5)),labels = None))\n",
    "tpr_logregCV = tp_logregCV/(tp_logregCV + fn_logregCV)\n",
    "fpr_logregCV = fp_logregCV/(fp_logregCV + tn_logregCV)\n",
    "\n",
    "# Compute true positive rate of the fitted classifier at threshold\n",
    "print (\"\\ntrue positive rate at threshold \" + str(threshold) + \" :  \" + str(tpr_logregCV))\n",
    "\n",
    "# Compute false positive rate of the fitted classifier at threshold\n",
    "fpr_logregCV = fp_logregCV/(fp_logregCV + tn_logregCV)\n",
    "print (\"\\nfalse positive rate at threshold \" + str(threshold) + \":  \" + str(fpr_logregCV))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: How do the two ROC curves compare?\n",
    "\n",
    "The fitted classifier ROC curve is much better, its True Positive values are always larger than the all 0's classifier ROC curve values for any given False Positive value, or, put another way, tends toward the upper left quadrant of the plot more than the all 0's classifier ROC curve.  The all 0's classifier ROC curve is a straight line with slope = 1 and y-intercept at x = 0.  This is equivalent to a truly random (and therefore useless) classifier, meaning, it's no better at identifying true positives than flipping a coin.  Such as classifier will have an area under the ROC curve (AUC) of 0.5, the lowest possible AUC.\n",
    "\n",
    "#### Q: Compute the highest TPR that can be achieved by the classifier at each of the following FPR's, and the thresholds at which they are achieved. Based on your results, comment on how the threshold influences a classifier's FPR. Based on your results, comment on how the threshold influences a classifier's FPR.\n",
    "    \n",
    "  \n",
    "FPR | TPR |  Predicted Class<br> Probability Threshold|\n",
    "-------------:|-------------:|-------------:|\n",
    "0 | 0.0|0.9999|\n",
    "0.1| 0.8077|0.0057|\n",
    "0.5| 0.9615|0.0002|\n",
    "0.9| 0.9904|6.7004874287e-09|\n",
    "\n",
    "Lowering the predicted class probability threshold corresponds to increasing the classifier's false positive rate (FPR).\n",
    "\n",
    "#### Q: Suppose a clinician told you that diagnosing a cancer patient as normal is twice as critical an error as diagnosing a normal patient as having cancer. Based on this information, what threshold would you recommend the clinician to use? What is the TPR and FPR of the classifier at this threshold?\n",
    "\n",
    "Based on this criteria, we took two approaches:\n",
    "\n",
    "**1)** *Visual approach* - We constructed a figure, see above, that consists of two plots, FNR and FPR both scaled corresponding to meet the clinician's criteria.  We could then visually determine the point at which the two plots intersect, this corresponds to the predicted class probability threshold at which diagnosing a cancer patient as normal is twice as bad as diagnosing a normal patient with cancer.\n",
    "\n",
    "**2)** *Iterative approach* - We iterate through a range of predicted class probability thresholds between 0 and 1 to determine at which threshold the ratio of the number of False Positives to False Negative is 2.  \n",
    "\n",
    "Both the visual and iterative approach produced a predicted class probability threshold of 0.116, and we verified our fitted model yields 50 False Negatives and 100 False Positive when we use this threshold.  The TPR and FPR of the classifier at this threshold is 0.5192 and 0.0059, respectively.\n",
    "\n",
    "#### Q; Compute the area under the ROC curve (AUC) for both the fitted classifier and the all 0's classifier. How does the difference in the AUCs of the two classifiers compare with the difference between their classification accuracies in Question 1, Part 2(A)?\n",
    "\n",
    "The area under the ROC curve (AUC) for both the fitted classifier and the all 0's classifier is 0.93 and 0.5, respectively, as shown in the ROC plot.  An AUC of 0.5 is the lowest possible AUC and it corresponds to a truly random (useless) classifier as implied earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3: Missing data\n",
    "\n",
    "In this problem you are given a different data set, `hw6_dataset_missing.csv`, that is  similar to the one you used above (same column definitions and same conditions), however this data set contains missing values. \n",
    "\n",
    "*Note*: be careful of reading/treating column names and row names in this data set as well, it *may* be different than the first data set.\n",
    "\n",
    "\n",
    "1. Remove all observations that contain and missing values, split the dataset into a 75-25 train-test split, and fit the regularized logistic regression as in Question 1 (use `LogisticRegressionCV` again to retune).  Report the overall classification rate and TPR in the test set.\n",
    "2. Restart with a fresh copy of the data in `hw6_dataset_missing.csv` and impute the missing data via mean imputation.  Split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.  \n",
    "3. Again restart with a fresh copy of the data in `hw6_dataset_missing.csv` and impute the missing data via a model-based imputation method. Once again split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.  \n",
    "4. Compare the results in the 3 previous parts of this problem.  Prepare a paragraph (5-6 sentences) discussing the results, the computational complexity of the methods, and conjecture and explain why you get the results that you see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def split_data(df):\n",
    "    msk = np.random.rand(len(df)) < 0.75\n",
    "    data_train = df[msk]\n",
    "    data_test = df[~msk]\n",
    "    \n",
    "    ytrain = data_train.iloc[:,-1]\n",
    "    Xtrain = data_train.drop(data_test.columns[len(data_test.columns)-1], axis=1)\n",
    "\n",
    "    ytest = data_test.iloc[:,-1]\n",
    "    Xtest = data_test.drop(data_test.columns[len(data_test.columns)-1], axis=1)\n",
    "    return (ytrain, Xtrain, ytest, Xtest)\n",
    "    \n",
    "def split_and_test(df):\n",
    "    ytrain, Xtrain, ytest, Xtest = split_data(df)\n",
    "    logregcv = LogisticRegressionCV(penalty='l2')\n",
    "    logregcv.fit(Xtrain, ytrain)\n",
    "    print(logregcv.score(Xtest, ytest))\n",
    "    test_preds = logregcv.predict(Xtest)\n",
    "    C = confusion_matrix(ytest, test_preds, labels=None)\n",
    "    print(C)\n",
    "\n",
    "    print(\"\\nTrue Positive Rate:\")\n",
    "    print(C[1][1] / (C[1][1] + C[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93     3894\n",
       "94     3903\n",
       "95     3897\n",
       "96     3913\n",
       "97     3899\n",
       "98     3903\n",
       "99     3911\n",
       "100    3907\n",
       "101    3889\n",
       "102    3953\n",
       "103    3911\n",
       "104    3928\n",
       "105    3891\n",
       "106    3892\n",
       "107    3928\n",
       "108    3909\n",
       "109    3914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing = pd.read_csv('./data/HW6_dataset_missing.csv')\n",
    "missing_columns = df_missing.columns[df_missing.isnull().any()]\n",
    "# How many NaNs are there in each column with missing data?\n",
    "df_missing[missing_columns].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[362]]\n",
      "\n",
      "True Positive Rate:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-505-aa64a6fb5ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_dropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_missing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplit_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-504-017649a889fe>\u001b[0m in \u001b[0;36msplit_and_test\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTrue Positive Rate:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#Drop missing datapoints\n",
    "df_dropped = df_missing.dropna(axis=0, how='any', inplace=False)\n",
    "\n",
    "split_and_test(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996005113455\n",
      "[[6227    0]\n",
      " [  25    6]]\n",
      "\n",
      "True Positive Rate:\n",
      "0.193548387097\n"
     ]
    }
   ],
   "source": [
    "#  Restart with a fresh copy of the data in hw6_dataset_missing.csv and \n",
    "#  impute the missing data via a model-based imputation method. \n",
    "#  Split the data 75-25 and fit the regularized logistic regression model. \n",
    "#  Report the overall classification rate and TPR in the test set.\n",
    "#  Determine which columns contain NaNs\n",
    "\n",
    "#df = pd.read_csv('./data/HW6_dataset_missing.csv')\n",
    "#df_full = df.copy()  \n",
    "#df_full.dropna(axis=0, how='any', inplace=True)  # df_full contains no NaNs\n",
    "df_mean = df_missing.copy()\n",
    "\n",
    "# Iterate through columns with Nan\n",
    "for missing_column in missing_columns:\n",
    "    # Find means of those columns\n",
    "    df_mean[missing_column] = df_missing[missing_column].fillna(df_mean[missing_column].mean())\n",
    "split_and_test(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993766980981\n",
      "[[6210    3]\n",
      " [  36    8]]\n",
      "\n",
      "True Positive Rate:\n",
      "0.181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Again restart with a fresh copy of the data in hw6_dataset_missing.csv and \n",
    "# impute the missing data via a model-based imputation method. \n",
    "# Once again split the data 75-25 and fit the regularized logistic regression model. \n",
    "# Report the overall classification rate and TPR in the test set.\n",
    "\n",
    "# Remove predictor\n",
    "df_full = df_missing.copy()\n",
    "df_impute = df_missing.copy()\n",
    "\n",
    "#Drop missing rows\n",
    "df_full.dropna(axis=0, how='any', inplace=True)  # df_full contains no NaNs\n",
    "# Drop missing columns for X_imp predictions\n",
    "X_imp  = df_full.drop(missing_columns, axis = 1)\n",
    "\n",
    "# Iterate through previously-found columns with Nan\n",
    "for missing_column in missing_columns:\n",
    "    #  Build linear regression model using dataset without columns containing NaNs\n",
    "    y_imp  = df_full[missing_column]\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_imp, y_imp)\n",
    "    \n",
    "    y_hat = linreg.predict(X_imp)\n",
    "\n",
    "    #  Get rows with missing indexes and then Drop column we're trying to impute\n",
    "    X_missing_rows_df = df_missing[df_missing[missing_column].isnull()]\n",
    "    X_missing_indexes = df_missing[df_missing[missing_column].isnull()].index\n",
    "\n",
    "    X_missing_rows_df = X_missing_rows_df.drop(missing_columns, axis = 1)\n",
    "\n",
    "    y_missing_rows = linreg.predict(X_missing_rows_df)\n",
    "\n",
    "    y_missing_noise = y_missing_rows + np.random.normal(loc = 0,\n",
    "                                                   scale = np.sqrt(mean_squared_error(y_imp,y_hat)),\n",
    "                                                   size  = y_missing_rows.shape[0])\n",
    "    missing_series = pd.Series(data = y_missing_noise, index = X_missing_indexes)\n",
    "    \n",
    "    #back to the data set with missingness and impute the predictions\n",
    "    df_impute[missing_column] = df_impute[missing_column].fillna(missing_series)\n",
    "\n",
    "split_and_test(df_impute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Remove all observations that contain and missing values, split the dataset into a 75-25 train-test split, and fit the regularized logistic regression as in Question 1. Report the overall classification rate and TPR in the test set.\n",
    "\n",
    "Overall classification rate: 0.997\n",
    "True positive rate: 0.0\n",
    "\n",
    "#### Q: Restart with a fresh copy of the data in hw6_dataset_missing.csv and impute the missing data via mean imputation. Split the data 75-25 and fit the regularized logistic regression model. Report the overall classification rate and TPR in the test set.\n",
    "\n",
    "Overall classification rate: 0.993\n",
    "True positive rate: 0.143\n",
    "\n",
    "#### Q: Impute the missing data via a model-based imputation method. Once again split the data 75-25 and fit the regularized logistic regression model. Report the overall classification rate and TPR in the test set.\n",
    "\n",
    "Overall classification rate: 0.994\n",
    "True positive rate: 0.114\n",
    "\n",
    "#### Q: Compare the results in the 3 previous parts of this problem. Prepare a paragraph (5-6 sentences) discussing the results, the computational complexity of the methods, and conjecture and explain why you get the results that you see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
